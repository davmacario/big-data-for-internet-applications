{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75809904-06d8-43c8-a607-dbb34b65a4f0",
   "metadata": {},
   "source": [
    "# Example 3 - simulation\n",
    "\n",
    "## Part 1 - MCQ\n",
    "\n",
    "1. d - SparkStreaming provides Checkpoints to recover from failures;\n",
    "2. d - The accumulator is used to count the words containing less than 3 letters, while the value 'v' is the sum of the lengths of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437da4d-2692-4b71-bd51-9b601fc1f1c8",
   "metadata": {},
   "source": [
    "## Part 2 - Problems\n",
    "\n",
    "### 1 - High cpu usage in the working hours of may 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68a0b408-a031-44e3-b5c7-a8756bafb0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/26 15:19:38 INFO fs.TrashPolicyDefault: Moved: 'hdfs://BigDataHA/user/s315054/exam_sim/example3/p01' to trash at: hdfs://BigDataHA/user/s315054/.Trash/Current/user/s315054/exam_sim/example3/p01\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/s315054/exam_sim/example3/p01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1978bed0-a805-4122-b9bc-d46675202a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDDs\n",
    "import sys\n",
    "\n",
    "# out_file_1 = sys.argv[1]\n",
    "# in_file = sys.argv[2]\n",
    "\n",
    "out_file_1 = '/user/s315054/exam_sim/example3/p01'\n",
    "in_file = '/data/students/bigdata_internet/exam_examples_data/example3_data/PerformanceLog.txt'\n",
    "\n",
    "in_RDD = sc.textFile(in_file).map(lambda l: l.split(','))\\\n",
    "    .filter(lambda lst: int(lst[0].split('/')[0]) == 2018 and int(lst[0].split('/')[1]) == 5 and (int(lst[1].split(':')[0]) >= 9 and int(lst[1].split(':')[0]) < 18))\n",
    "\n",
    "crit_RDD = in_RDD.filter(lambda l: float(l[3]) > 99.8).map(lambda el: (el[2], el[3])).mapValues(lambda v1: 1)\\\n",
    "    .reduceByKey(lambda v1, v2: v1+v2).filter(lambda el: int(el[1]) > 10000).keys()\n",
    "\n",
    "crit_RDD.saveAsTextFile(out_file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78674990-0da1-4a83-a9b1-a3a098d8f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2018/05/01', '15:40', 'VS1', '10.5', '0.5'],\n",
       " ['2018/05/01', '15:41', 'VS1', '10.5', '0.5'],\n",
       " ['2018/05/01', '15:42', 'VS1', '10.5', '0.5'],\n",
       " ['2018/05/01', '15:43', 'VS1', '10.5', '0.5'],\n",
       " ['2018/05/01', '15:40', 'VS2', '99.9', '100.0'],\n",
       " ['2018/05/01', '15:41', 'VS2', '100.0', '0.5'],\n",
       " ['2018/05/01', '15:42', 'VS2', '98.5', '0.5'],\n",
       " ['2018/05/01', '15:43', 'VS2', '90.5', '0.5'],\n",
       " ['2018/05/01', '09:43', 'VS3', '90.4', '1.5'],\n",
       " ['2018/05/01', '10:43', 'VS3', '90.4', '1.5'],\n",
       " ['2018/05/01', '11:43', 'VS3', '90.4', '1.5'],\n",
       " ['2018/05/01', '12:43', 'VS3', '9.4', '1.5'],\n",
       " ['2018/05/01', '13:43', 'VS3', '90.4', '1.5'],\n",
       " ['2018/05/01', '14:43', 'VS3', '9.4', '1.5'],\n",
       " ['2018/05/01', '15:43', 'VS3', '8.4', '1.5'],\n",
       " ['2018/05/01', '16:43', 'VS3', '90.4', '1.5'],\n",
       " ['2018/05/01', '17:43', 'VS3', '90.4', '1.5']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d06f68-2f8b-408d-aa6c-66c5d9f2847f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb6efb-89a4-4310-b9a8-37147cb7bb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c5494-4d60-47b0-9889-c7101dc96375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e378b-fcba-495a-9ac0-2113a4ea6154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb23bc88-ef0a-44aa-8b5a-78298fd1b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/26 15:21:36 WARN analysis.SimpleFunctionRegistry: The function getyear replaced a previously registered function.\n",
      "23/01/26 15:21:36 WARN analysis.SimpleFunctionRegistry: The function getmonth replaced a previously registered function.\n",
      "23/01/26 15:21:36 WARN analysis.SimpleFunctionRegistry: The function gethour replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "# DFs\n",
    "import sys\n",
    "\n",
    "# out_file_1 = sys.argv[1]\n",
    "# in_file = sys.argv[2]\n",
    "\n",
    "out_file_1 = '/user/s315054/exam_sim/example3/p01'\n",
    "in_file = '/data/students/bigdata_internet/exam_examples_data/example3_data/PerformanceLog.txt'\n",
    "\n",
    "spark.udf.register('getYear', lambda date: int(date.split('/')[0]))\n",
    "spark.udf.register('getMonth', lambda date: int(date.split('/')[1]))\n",
    "spark.udf.register('getHour', lambda hour: int(hour.split(':')[0]))\n",
    "\n",
    "\n",
    "in_DF = spark.read.load(in_file, format='csv', sep=',', header=False, inferSchema=True)\\\n",
    "    .withColumnRenamed('_c0', 'date')\\\n",
    "    .withColumnRenamed('_c1', 'hour')\\\n",
    "    .withColumnRenamed('_c2', 'vsid')\\\n",
    "    .withColumnRenamed('_c3', 'cpu')\\\n",
    "    .withColumnRenamed('_c4', 'ram')\n",
    "\n",
    "inter_DF = in_DF.filter(\"getYear(date) == 2018 AND getMonth(date) == 5 AND getHour(hour) >= 9 AND getHour(hour) < 18\")\n",
    "\n",
    "inter_DF.createOrReplaceTempView('table_1_1')\n",
    "\n",
    "out_DF = spark.sql(\"\"\"\n",
    "                SELECT vsid\n",
    "                FROM table_1_1\n",
    "                WHERE cpu > 99.8\n",
    "                \"\"\").groupBy('vsid').agg({'*': 'count'}).filter('count(1)>10000').select('vsid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebc94bb3-bfd4-4190-8fc3-82f6b403947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|vsid|count(1)|\n",
      "+----+--------+\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d98ad6-fba6-41c8-a98e-197f79148a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71296d3-9352-42fa-8a79-118594bd4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f801a31-ef8b-456a-8bc4-2e8b54718c65",
   "metadata": {},
   "source": [
    "### 2a - Critical VSID, hour pairs, may 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f85a2-8922-4bb8-a631-fd444fa78a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /user/s315054/exam_sim/example3/p02a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64efa3ba-d56a-4bf3-85c5-f5fe7f47fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# CPUthr = sys.argv[1]\n",
    "# RAMthr = sys.argv[2]\n",
    "\n",
    "CPUthr = 50.\n",
    "RAMthr = 20.\n",
    "\n",
    "in_file = '/data/students/bigdata_internet/exam_examples_data/example3_data/PerformanceLog.txt'\n",
    "out_file_2a = '/user/s315054/exam_sim/example3/p02a'\n",
    "\n",
    "in_RDD = sc.textFile(in_file).map(lambda line: line.split(','))    # Initial RDD\n",
    "filter_RDD = in_RDD.filter(lambda l: int(l[0].split('/')[0]) == 2018 and int(l[0].split('/')[1]) == 5)\\\n",
    "        .map(lambda l: ((l[2], int(l[1].split(':')[0])), (float(l[3]), float(l[4]), 1) ))      # Keys: (VSID, hour), value (CPUusage, RAMusage, 1)\n",
    "\n",
    "red_RDD = filter_RDD.reduceByKey(lambda v1, v2: (v1[0] + v2[0], v1[1] + v2[1], v1[2] + v2[2])).mapValues(lambda v: (v[0]/v[2], v[1]/v[2]))\n",
    "\n",
    "final_RDD = red_RDD.filter(lambda el: el[1][0] > CPUthr and el[1][1] > RAMthr)\n",
    "\n",
    "## Need to just keep keys\n",
    "out_RDD = final_RDD.keys().map(lambda el: f\"{el[0]}_{el[1]}\")\n",
    "out_RDD.saveAsTextFile(out_file_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83b5c723-9cb3-4f8f-90d5-92a600a867b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('VS2', 15), (97.225, 25.375))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9774f6e6-cf57-4fd4-9de1-874dd148091d",
   "metadata": {},
   "source": [
    "###  2b - Daily unbalanced usage of the CPU, May 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "528307a9-1064-4f3e-8680-cef53efdc9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/29 08:52:35 INFO fs.TrashPolicyDefault: Moved: 'hdfs://BigDataHA/user/s315054/exam_sim/example3/p02b' to trash at: hdfs://BigDataHA/user/s315054/.Trash/Current/user/s315054/exam_sim/example3/p02b1674982355294\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/s315054/exam_sim/example3/p02b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736cee8e-0a8c-4689-9a43-81dcba94b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_2b = '/user/s315054/exam_sim/example3/p02b'\n",
    "\n",
    "# Start from in_RDD, create pairs (VSID, date) and count the number of max. cpu > 90 and n. of max CPU < 10\n",
    "\n",
    "# First, isolate elements in May 2018, then map them to key-value pair having as key (VSID, date, hour), before finding the max for each hour\n",
    "f1_RDD = in_RDD.filter(lambda l: int(l[0].split('/')[0]) == 2018 and int(l[0].split('/')[1]) == 5)\\\n",
    "        .map(lambda l: (( l[2], l[0], int(l[1].split(':')[0]) ), float(l[3]) ))\n",
    "###################### VSID^, date^,        hour^,                CPU%^\n",
    "\n",
    "# Find max for each hour:\n",
    "f2_RDD = f1_RDD.reduceByKey(lambda v1, v2: max(v1, v2))\n",
    "\n",
    "# Remap to get keys of the type (vsid, date) and map these elements' values to (1 if >90, 1 if <90)\n",
    "f3_RDD = f2_RDD.map(lambda e: ((e[0][0], e[0][1]), (int(e[1] > 90), int(e[1] < 10)) ))\n",
    "\n",
    "# Reduce by key to sum corresponding values in the value tuples, then filter\n",
    "final_RDD = f3_RDD.reduceByKey(lambda v1, v2: (v1[0] + v2[0], v1[1] + v2[1])).filter(lambda el: el[1][0]>=8 and el[1][1] >= 8).keys()\n",
    "\n",
    "# Produce the required output\n",
    "output_RDD = final_RDD.map(lambda k: f\"{k[0]}_{k[1].replace('/', '-')}\")\n",
    "output_RDD.saveAsTextFile(out_file_2b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c782190-519f-48d4-a06f-5c0375bc3104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VS3_2018-05-01']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72341c6-a92f-4516-8122-64e8fadceb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "704a9ea8-0243-4896-90f1-c118fd50702e",
   "metadata": {},
   "source": [
    "#### Using DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd23276d-c4fc-429f-b702-b9d092b015ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/29 09:43:37 WARN analysis.SimpleFunctionRegistry: The function getyear replaced a previously registered function.\n",
      "23/01/29 09:43:37 WARN analysis.SimpleFunctionRegistry: The function getmonth replaced a previously registered function.\n",
      "23/01/29 09:43:37 WARN analysis.SimpleFunctionRegistry: The function gethour replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "in_file = '/data/students/bigdata_internet/exam_examples_data/example3_data/PerformanceLog.txt'\n",
    "\n",
    "####### a\n",
    "# CPU_thresh = sys.argv[1]\n",
    "# RAM_thresh = sys.argv[2]\n",
    "CPU_thresh = 50.\n",
    "RAM_thresh = 20.\n",
    "\n",
    "spark.udf.register('getYear', lambda el: int(el.split('/')[0]))\n",
    "spark.udf.register('getMonth', lambda el: int(el.split('/')[1]))\n",
    "spark.udf.register('getHour', lambda el: el.split(':')[0])\n",
    "\n",
    "in_DF = spark.read.load(in_file, format='csv', sep=',', header=False)\\\n",
    "        .withColumnRenamed('_c0', 'date').withColumnRenamed('_c1', 'time')\\\n",
    "        .withColumnRenamed('_c2', 'vsID').withColumnRenamed('_c3', 'CPU')\\\n",
    "        .withColumnRenamed('_c4', 'RAM')\n",
    "\n",
    "may_DF = in_DF.filter(\"getYear(date) == 2018 AND getMonth(date) == 5\")\n",
    "\n",
    "start_DF = may_DF.selectExpr('vsID', 'getHour(time) AS hour', \"CPU\", \"RAM\").groupBy(\"vsID\", \"hour\").agg({\"CPU\":\"avg\", \"RAM\": \"avg\"})\\\n",
    "                .withColumnRenamed('avg(CPU)', 'avg_CPU').withColumnRenamed('avg(RAM)', \"avg_RAM\")\\\n",
    "                .createOrReplaceTempView('may_2018')\n",
    "\n",
    "out_DF = spark.sql(f\" \\\n",
    "                    SELECT vsID, hour\\\n",
    "                    FROM may_2018\\\n",
    "                    WHERE avg_CPU > {CPU_thresh} AND avg_RAM > {RAM_thresh}\\\n",
    "                    \")\n",
    "\n",
    "# Since the header is not needed, can move to RDDs\n",
    "out_DF2RDD = out_DF.rdd.map(lambda el: f\"{el[0]}_{el[1]}\")\n",
    "#out_DF2RDD.saveAsTextFile(out_file_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92cdea-848c-473f-aae3-ec62254a44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /user/s315054/exam_sim/example3/p02b_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e912562-6c9a-4012-b595-b03fdc9d95d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2b\n",
    "\n",
    "out_file_2b_df = '/user/s315054/exam_sim/example3/p02b_df'\n",
    "\n",
    "# Start from may_DF\n",
    "# Need to evaluate the maximum value of CPU usage in each hour\n",
    "# Columns: date, time, vsID, CPU, RAM\n",
    "\n",
    "sel_DF = may_DF.selectExpr('vsID', 'date', 'getHour(time) AS hour', 'CPU')\\\n",
    "        .groupBy('vsID', 'date', 'hour').agg({'CPU':'max'})\\\n",
    "        .withColumnRenamed('max(CPU)', 'max_CPU')\n",
    "\n",
    "sel_DF.createOrReplaceTempView('selected')\n",
    "\n",
    "count_DF = spark.sql(\"\\\n",
    "            SELECT vsID, date\\\n",
    "            FROM selected\\\n",
    "            GROUP BY vsID, date\\\n",
    "            HAVING count(max_CPU > 90) >= 8 AND count(max_CPU < 10) >= 8\\\n",
    "            \")\n",
    "\n",
    "count_DF.write.csv(out_file_2b_df, header=False, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f41724-d986-42a6-88af-b0ef7cca12cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c5a7e-ff11-4b4f-b7ff-5c87e60dc332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c369b-ad2f-449b-9cf0-fbb76a0f75a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3eb5b5af-4230-4028-80bd-9bbe7921210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+----+---+\n",
      "|      date| time|vsID| CPU|RAM|\n",
      "+----------+-----+----+----+---+\n",
      "|2018/05/01|15:40| VS1|10.5|0.5|\n",
      "|2018/05/01|15:41| VS1|10.5|0.5|\n",
      "|2018/05/01|15:42| VS1|10.5|0.5|\n",
      "|2018/05/01|15:43| VS1|10.5|0.5|\n",
      "|2018/05/01|05:40| VS1|10.5|0.5|\n",
      "+----------+-----+----+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_file = '/data/students/bigdata_internet/exam_examples_data/example3_data/PerformanceLog.txt'\n",
    "\n",
    "in_DF = spark.read.load(in_file, format='csv', sep=',', header=False).toDF('date', 'time', 'vsID', 'CPU', 'RAM')\n",
    "in_DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71071c-0577-4815-bbb0-385bdfff2708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824d6b0-6ef3-47c2-a17c-2ac5a1c1af5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
