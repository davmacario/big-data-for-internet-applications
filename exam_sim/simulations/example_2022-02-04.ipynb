{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b76bda5-cbba-4d72-af00-c39b60dbf71d",
   "metadata": {},
   "source": [
    "# Exam - 2 feb 2022\n",
    "\n",
    "## Part 1 - MCQ\n",
    "\n",
    "[...]\n",
    "\n",
    "## Part 2 - Exercises\n",
    "\n",
    "### Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6aefb8-674a-4922-8dee-f8dd42f52589",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_actions = './Actions.txt'\n",
    "input_apps = './Apps.txt'\n",
    "out_path = '/user/s315054/exam_sim/2022-02-04_1'\n",
    "\n",
    "actions_DF = spark.read.load(input_actions, format='csv', header=False, inferSchema=True)\\\n",
    "                    .toDF('userID', 'appID', 'timestamp', 'action')\n",
    "actions_DF.createOrReplaceTempView('actions_table')\n",
    "\n",
    "apps_DF = spark.read.load(input_apps, format='csv', header=False, inferSchema=True)\\\n",
    "                    .toDF('appID', 'appname', 'price', 'category', 'commpany')\n",
    "apps_DF.createOrReplaceTempView('apps_table')\n",
    "\n",
    "spark.udf.register('getYear', lambda ts: int(ts.split('/')[0]))\n",
    "\n",
    "# Group by user and app, having downloaded the app at least once\n",
    "out_DF = spark.sql(\"\"\"\n",
    "            SELECT appID, count(distinct(userID))\n",
    "            FROM actions_table, apps_table\n",
    "            WHERE actions_table.appID == apps_table.appID AND apps_table.price == 0 AND actions_table == 'Install'\n",
    "            GROUP BY appID\n",
    "            HAVING count(distinct(userID)) > 1000000\n",
    "\"\"\")\n",
    "\n",
    "# Join on the free apps to isolate them\n",
    "out_DF = selected_DF.join(apps_DF.filter('price == 0').select('appID'), 'appID')\n",
    "\n",
    "out_DF.write.csv(out_path, sep=',', header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031eeb0d-597a-4567-ba95-98189ebe2508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db15bf35-7ce0-4fff-ab5c-8868c6ab8a13",
   "metadata": {},
   "source": [
    "### Ex 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c93d6-11a0-4c07-915d-1c85343b0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_2a = 'outFolder_ex2_1'\n",
    "\n",
    "# Categories with average price > 10 euri\n",
    "apps_DF = spark.read.load(input_apps, format='csv', header=False, inferSchema=True)\\\n",
    "                    .toDF('appID', 'appname', 'price', 'category', 'commpany')\n",
    "apps_DF.createOrReplaceTempView('apps_table')\n",
    "\n",
    "out_2a_DF = spark.sql(\"\"\"\n",
    "            SELECT category\n",
    "            FROM apps_table\n",
    "            WHERE price > 0\n",
    "            GROUP BY category\n",
    "            HAVING avg(price) > 10\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebe3b1-1be8-4138-ad82-acbe16bcd9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b626040-f5fb-4aee-8a01-b24f7f285784",
   "metadata": {},
   "source": [
    "###  Ex 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d27c27-6992-49e4-bdb5-8c741b7a6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_2b = 'outFolder_ex2_2'\n",
    "\n",
    "actions_DF = spark.read.load(input_actions, format='csv', header=False, inferSchema=True)\\\n",
    "                    .toDF('userID', 'appID', 'timestamp', 'action')\n",
    "\n",
    "actions_DF.createOrReplaceTempView('act')\n",
    "\n",
    "spark.udf.register('getYear', lambda ts: int(ts.split('/')[0]))\n",
    "\n",
    "# Isolate apps not intalled before 2021\n",
    "# Also check for n. intalls from 2021 > 0 in case there are records of 'downloaded' from 2021 on, but not installed\n",
    "new_apps_DF = spark.sql(\"\"\"\n",
    "        SELECT appID\n",
    "        FROM act\n",
    "        WHERE action == 'Installed'\n",
    "        GROUP BY appID\n",
    "        HAVING sum(CAST(getYear(timestamp) <= 2020 AS int)) == 0 AND sum(CAST(getYear(timestamp) >= 2021 AS int)) > 0\n",
    "\"\"\")\n",
    "new_apps_DF.createOrReplaceTempView('new_apps')\n",
    "\n",
    "# Keep apps downloaded from 2021 on\n",
    "# Keep users which have them installed\n",
    "installed_DF = spark.sql(\"\"\"\n",
    "        SELECT act.appID\n",
    "        FROM act, new_apps\n",
    "        WHERE act.appID == new_apps.appID\n",
    "        GROUP BY act.appID, act.userID\n",
    "        HAVING sum(CAST(act.action == 'Install' AS int)) > sum(CAST(act.action == 'Remove' AS int))\n",
    "\"\"\")\n",
    "\n",
    "intalled_DF.createOrReplaceTempView('installed')\n",
    "\n",
    "out_2_2_DF = spark.sql(\"\"\"\n",
    "        SELECT appID\n",
    "        FROM installed\n",
    "        GROUP BY appID\n",
    "        HAVING count(userID) >= 100000\n",
    "\"\"\")\n",
    "\n",
    "out_2_2_DF.write.csv(out_path_2b, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71213749-142f-4add-9afb-7a3dfc80f074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f12919-64ca-4383-b6cb-331caf11ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns the couples appID, userID for which the app was not downloaded\n",
    "# NO - there could be apps which have been downloaded before 2021 by some users and not by others.\n",
    "# These apps would have been included in the query \n",
    "# (because of the users which did not download them prior to 2021)\n",
    "spark.sql(\"\"\"\n",
    "        SELECT appID, userID\n",
    "        FROM act\n",
    "        GROUP BY appID, userID\n",
    "        HAVING sum(CAST((getYear(timestamp) <= 2020 AND action == 'Installed') AS int)) == 0 AND sum(CAST((getYear(timestamp) >= 2021 AND action == 'Installed') AS int)) > 0\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6049b-020f-4439-b683-ffeef805f0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
