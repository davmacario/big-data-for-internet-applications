{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624ef130-227f-429e-8615-4b00c700f810",
   "metadata": {},
   "source": [
    "# Exam Example 4 - full simulation\n",
    "\n",
    "## Part 1 - MCQ\n",
    "\n",
    "1. The correct answer is b) 3 bock. Indeed, hdfs blocks can only contain part of one file, hence since `log2.txt` is bigger than 1 block size, 2 blocks are needed to store it (it cannot be stored together with the other file).\n",
    "2. a0 Cache `logsRDD`, since a count action is done on it and another is done on its descendant `distinctURLs`.\n",
    "\n",
    "## Part 2 - Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918eedf-dcbb-4a8d-9ca3-1e0ff2ba800e",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00940370-d2a7-4a9c-83d2-8416746e2685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014/05/21,15:16,5.32\n"
     ]
    }
   ],
   "source": [
    "# With RDDs:\n",
    "\n",
    "import sys\n",
    "\n",
    "#input_path = sys.argv[1]\n",
    "input_path = '/data/students/bigdata_internet/exam_examples_data/example4_data/Prices.txt'\n",
    "\n",
    "in_RDD = sc.textFile(input_path).map(lambda line: line.split(','))\n",
    "\n",
    "def simplify(l1, l2):\n",
    "    \n",
    "    dateHour1 = str(l1[0]) + ',' + str(l1[1])\n",
    "    dateHour2 = str(l2[0]) + ',' + str(l2[1])\n",
    "    \n",
    "    # Lowest price\n",
    "    if float(l1[3]) > float(l2[3]):\n",
    "        return l2\n",
    "    elif float(l1[3]) < float(l2[3]): \n",
    "        return l1\n",
    "    else:\n",
    "        if dateHour1 > dateHour2:\n",
    "            return l1\n",
    "        else:\n",
    "            return l2\n",
    "\n",
    "out_better = in_RDD.filter(lambda el: int(el[0].split('/')[0]) == 2014 and str(el[2]) == 'TSLA')\\\n",
    "        .reduce(simplify)\n",
    "\n",
    "out_def = out_better[0] + ',' + out_better[1] + ',' + out_better[3]\n",
    "\n",
    "print(out_def)\n",
    "\n",
    "# 2014/05/21,15:16,5.32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c149bf8-2754-4948-983b-83383ce5db46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2014/05/21', '15:16', '55.32'],\n",
       " ['2014/05/21', '15:12', '45.32'],\n",
       " ['2014/05/21', '15:08', '45.32'],\n",
       " ['2014/05/21', '15:04', '45.32'],\n",
       " ['2014/05/21', '15:00', '45.32'],\n",
       " ['2014/05/21', '15:10', '15.32'],\n",
       " ['2014/05/21', '15:06', '15.32'],\n",
       " ['2014/05/21', '15:02', '15.32'],\n",
       " ['2014/05/21', '15:16', '5.32'],\n",
       " ['2014/05/21', '15:14', '5.32']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15e806-77b1-494d-a55b-2ce2c30359e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With DFs\n",
    "\n",
    "spark.udf.register('getYear', lambda date: int(date.split('/')[0]))\n",
    "spark.udf.register('getMonth', lambda date: int(date.split('/')[1]))\n",
    "spark.udf.register('getDay', lambda date: int(date.split('/')[2]))\n",
    "spark.udf.register('getHour', lambda h: int(h.split(':')[0]))\n",
    "spark.udf.register('getMin', lambda h: int(h.split(':')[1]))\n",
    "\n",
    "in_DF_1 = spark.read.load(input_path, format='csv', header=False, inferSchema=True).asDF('date', 'time', 'stockID', 'price')\n",
    "\n",
    "in_DF_1.createOrReplaceTempView('input_tab')\n",
    "\n",
    "out_1_DF = in_DF_1.filter('stockID == \"TSLA\" AND getYear(date) == 2014')\\\n",
    "    .select('date', 'time', 'price').sort('price', 'getMonth(date)', 'getDay(date)', 'getHour(time)', 'getMin(time)')\n",
    "\n",
    "# NO NEED TO SORT THE WHOLE DF... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc35abc-c778-4133-9378-b8a8b3f5a5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14504c28-d8ec-4791-8d24-c70f374a170a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ab' > 'aa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a81a34-d63d-411a-b939-48b78e802d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa37a865-90ed-4ce9-b97f-3170b8fa0c17",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec02e21-b819-4c2b-ab14-0b51963f9abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /user/s315054/exam_sim/example4/ex2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fabb418-5c3a-48f6-9975-66d9f3b7142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/30 16:03:59 WARN analysis.SimpleFunctionRegistry: The function getyear replaced a previously registered function.\n",
      "23/01/30 16:03:59 WARN analysis.SimpleFunctionRegistry: The function getmonth replaced a previously registered function.\n",
      "23/01/30 16:03:59 WARN analysis.SimpleFunctionRegistry: The function getday replaced a previously registered function.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# With DFs\n",
    "\n",
    "# Part a\n",
    "import sys\n",
    "\n",
    "# input_f = sys.argv[1] \n",
    "# out_a = sys.argv[2]\n",
    "# out_b = sys.argv[3]\n",
    "\n",
    "#input_f = '/data/students/bigdata_internet/exam_examples_data/example4_data/Prices.txt'\n",
    "input_f = '/user/s315054/Prices.txt' \n",
    "out_a = '/user/s315054/exam_sim/example4/ex2a'\n",
    "out_b = '/user/s315054/exam_sim/example4/ex2b'\n",
    "\n",
    "in_DF = spark.read.load(input_f, format='csv', header=False).toDF('date', 'time', 'stockID', 'price')\n",
    "\n",
    "spark.udf.register('getYear', lambda date: int(date.split('/')[0]))\n",
    "spark.udf.register('getMonth', lambda date: int(date.split('/')[1]))\n",
    "spark.udf.register('getDay', lambda date: int(date.split('/')[2]))\n",
    "\n",
    "in_DF.createOrReplaceTempView('input_tab')\n",
    "\n",
    "# Isolate 2014 records, group them per date and id and take max and min prices for each\n",
    "filt_better_DF = spark.sql(\"\"\"\n",
    "        SELECT date, stockID, max(price), min(price)\n",
    "        FROM input_tab\n",
    "        WHERE getYear(date) == 2014\n",
    "        GROUP BY date, stockID\n",
    "\"\"\").withColumnRenamed('max(price)', 'max_price').withColumnRenamed('min(price)', 'min_price')\n",
    "\n",
    "# Only keep the ones in which the daily price variation is < 5\n",
    "# Then Group by ID and count the ones remaining for each stock\n",
    "less_5_daily_DF = filt_better_DF.filter(\"max_price - min_price < 5\")\\\n",
    "    .groupBy('stockID').agg({'*': 'count'}).withColumnRenamed('count(1)', 'n_variation_less_5')\n",
    "\n",
    "# Produce output:\n",
    "less_5_daily_DF.write.csv(out_a, header=False, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99e9e1bc-5fae-4dea-a505-8900b3e7ca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|stockID|count(1)|\n",
      "+-------+--------+\n",
      "|   GOOG|       2|\n",
      "|    FCA|       1|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "less_5_daily_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "169cc89a-8f1d-465c-a99b-9a3c7f5caa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/30 16:26:30 WARN analysis.SimpleFunctionRegistry: The function getprevday replaced a previously registered function.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Part b:\n",
    "import datetime\n",
    "\n",
    "dpv_DF = filt_better_DF.selectExpr('date', 'stockID', 'max_price - min_price AS dpv')\n",
    "\n",
    "#########\n",
    "def getPrevDay(date):\n",
    "    date1 = datetime.datetime.strptime(date, '%Y/%m/%d')\n",
    "    yesterday = date1 - datetime.timedelta(1)\n",
    "    return yesterday.strftime('%Y/%m/%d')\n",
    "\n",
    "spark.udf.register('getPrevDay', getPrevDay)\n",
    "\n",
    "with_yesterday_DF = dpv_DF.selectExpr('date', 'stockID', 'dpv', 'getPrevDay(date) AS yesterday')\n",
    "\n",
    "today_and_yesterday_DF = with_yesterday_DF.join(dpv_DF.withColumnRenamed('date', 'yesterday').withColumnRenamed('dpv', 'dpv_yesterday'), ['yesterday', 'stockID'])\n",
    "\n",
    "unstable_pairs_DF = today_and_yesterday_DF.filter(\"abs(dpv - dpv_yesterday) > 1\")\n",
    "\n",
    "unstable_pairs_DF.selectExpr('stockID', 'yesterday AS first_date').write.csv(out_b, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbe2f299-9743-4243-8ac6-4b860cfa67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023/01/29'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPrevDay('2023/01/30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd3fab6d-88b5-49ca-8227-0dbe1285a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+---+-------------+\n",
      "| yesterday|stockID|      date|dpv|dpv_yesterday|\n",
      "+----------+-------+----------+---+-------------+\n",
      "|2014/05/21|   GOOG|2014/05/22|2.0|         40.0|\n",
      "+----------+-------+----------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unstable_pairs_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca84c79-dcdb-4ffc-8b30-994581242292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ded7aa-194b-4398-81d4-ecea2aeb4fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "860eed17-b426-4499-b1b9-b556505f57f2",
   "metadata": {},
   "source": [
    "# Cazzeggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a92cc4fd-e1bc-4d2b-9fae-9ea51a432b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/01/30 18:58:33 WARN analysis.SimpleFunctionRegistry: The function makelst replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "spark.udf.register('makelst', lambda d: d.split('/'))\n",
    "\n",
    "withList = in_DF.selectExpr('makelst(date) AS date_list', 'time', 'stockID', 'price')\n",
    "\n",
    "#withList.select('date_lst.1').show()\n",
    "print(withList.collect()[0].asDict()['date_list'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d41baf19-fa42-433d-b0e0-98d10b45d9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| time| time|\n",
      "+-----+-----+\n",
      "|15:00|15:00|\n",
      "|15:02|15:02|\n",
      "|15:04|15:04|\n",
      "|15:06|15:06|\n",
      "|15:08|15:08|\n",
      "|15:10|15:10|\n",
      "|15:12|15:12|\n",
      "|15:14|15:14|\n",
      "|15:16|15:16|\n",
      "|15:16|15:16|\n",
      "|15:00|15:00|\n",
      "|15:02|15:02|\n",
      "|15:04|15:04|\n",
      "|15:06|15:06|\n",
      "|15:08|15:08|\n",
      "|15:10|15:10|\n",
      "|15:12|15:12|\n",
      "|15:14|15:14|\n",
      "|15:16|15:16|\n",
      "|15:16|15:16|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "withList.select('time', 'time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15590e00-a6f8-4535-b1d9-c1e8d42f4898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee93363-dfc8-43f9-aa95-39d7c63f0f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
