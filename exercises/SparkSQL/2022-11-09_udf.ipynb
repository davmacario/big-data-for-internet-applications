{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddda5bc6-3c33-4b32-9d49-25de0a38ace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-----+\n",
      "|     name|age| dept|\n",
      "+---------+---+-----+\n",
      "|    Paolo| 50|  DET|\n",
      "|     Luca| 40|DAUIN|\n",
      "|  Martino| 30|  DAD|\n",
      "|    Paolo| 25| DIST|\n",
      "|Francesca| 40|DAUIN|\n",
      "|    Paolo| 32|  DET|\n",
      "|     Luca| 56|  DAD|\n",
      "+---------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "path = \"/data/students/bigdata_internet/dataframe_examples/mycsv.csv\"\n",
    "df = spark.read.load(path, format=\"csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b092d336-c942-4a50-9505-0580a886d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('myTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb4e6fc9-8ab4-40ef-9ee5-a869cfa788f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|dept|count(dept)|\n",
      "+----+-----------+\n",
      "| DET|          1|\n",
      "| DAD|          1|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With SQL:\n",
    "df_out = spark.sql(\" SELECT dept, count(dept) \\\n",
    "          FROM myTable \\\n",
    "          WHERE age>45 \\\n",
    "          GROUP BY dept \\\n",
    "          ORDER BY dept DESC \\\n",
    "          \")\n",
    "df_out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a450f81f-78d6-47b6-a21c-fceb20994c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|dept|count(dept)|\n",
      "+----+-----------+\n",
      "| DET|          1|\n",
      "| DAD|          1|\n",
      "+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# With DF:\n",
    "df_filt = df.filter('age>45').groupBy(\"dept\").agg({'dept':'count'}).sort('dept', ascending=False)\n",
    "df_filt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d4419f4-e8dd-4d36-b641-eeab18b80e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a UDF:\n",
    "spark.udf.register(\"myFunct\", lambda x: len(x)+25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9ddcae5-8f48-4e00-875b-27b285f6aec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|myFunct(name)|\n",
      "+-------------+\n",
      "|           30|\n",
      "|           29|\n",
      "|           32|\n",
      "|           30|\n",
      "|           34|\n",
      "|           30|\n",
      "|           29|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the UDF to sum 25 to the lengthof each name and store each result in a row of a new DF\n",
    "\n",
    "# DF\n",
    "df.selectExpr(\"myFunct(name)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "197b5444-7150-4d6c-b8b7-05f5544fc3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|myFunct(name)|\n",
      "+-------------+\n",
      "|           30|\n",
      "|           29|\n",
      "|           32|\n",
      "|           30|\n",
      "|           34|\n",
      "|           30|\n",
      "|           29|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"SELECT myFunct(name) FROM myTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb0c3dfb-92d4-493c-958b-9da9e66c2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By creating a standalone python function:\n",
    "def myFunct2(x):\n",
    "    res = len(str(x)) + 25\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e96f5b0-67c3-4fdd-a9a2-3ec08c6aa206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.myFunct2(x)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: the name of the SQL function can (but shouldn't) be different from the one of the function just defined\n",
    "spark.udf.register('myFunct2', myFunct2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc1a1d6d-c605-4f11-8092-df2bf0cf7bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|myFunct2(name)|\n",
      "+--------------+\n",
      "|            30|\n",
      "|            29|\n",
      "|            32|\n",
      "|            30|\n",
      "|            34|\n",
      "|            30|\n",
      "|            29|\n",
      "+--------------+\n",
      "\n",
      "+--------------+\n",
      "|myFunct2(name)|\n",
      "+--------------+\n",
      "|            30|\n",
      "|            29|\n",
      "|            32|\n",
      "|            30|\n",
      "|            34|\n",
      "|            30|\n",
      "|            29|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DF\n",
    "df.selectExpr(\"myFunct2(name)\").show()\n",
    "\n",
    "# SQL\n",
    "spark.sql(\"SELECT myFunct2(name) FROM myTable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c3003-0bc6-4ab3-825f-5c9df57d16db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
